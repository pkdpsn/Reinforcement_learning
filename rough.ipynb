{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete,Box \n",
    "import numpy as np\n",
    "import random\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import pygame\n",
    "white = (255, 255, 255)\n",
    "colors = [\n",
    "    (0, 0, 255),  # Blue\n",
    "    (0, 255, 0),  # Green\n",
    "    (255, 0, 0),  # Red\n",
    "    (255, 255, 0),  # Yellow\n",
    "    (255, 0, 255),  # Magenta\n",
    "    (0, 255, 255),  # Cyan\n",
    "    (128, 0, 0),  # Maroon\n",
    "    (0, 128, 0),  # Olive\n",
    "    (128, 128, 0),  # Yellow Green\n",
    "    (0, 0, 128),  # Navy\n",
    "    (128, 0, 128),  # Purple\n",
    "    (0, 128, 128),  # Teal\n",
    "    (128, 128, 128),  # Gray\n",
    "    (255, 165, 0)  # Orange (for special cell)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class rlEnv(Env):\n",
    "    \n",
    "    def __init__(self, W, H):\n",
    "        super(rlEnv, self).__init__()\n",
    "        self.W = W\n",
    "        self.H = H\n",
    "        self.stepsize = (2 / self.W)\n",
    "        self.gravity = 9.81\n",
    "        self.truncated = False\n",
    "        self.done = False\n",
    "        self.action_space = Discrete(4)\n",
    "        self.observation_space = Discrete(W * H)\n",
    "        self.grid = np.zeros((H, W))\n",
    "        for i in range(W):\n",
    "            for j in range(H):\n",
    "                x = -3 + i * (6 / self.W)\n",
    "                y = -3 + j * (6 / self.H)\n",
    "                self.grid[j, i] = 16 * 0.4 * (x**2 + y**2 - 1/4)**2 if x**2 + y**2 < 1/4 else 0\n",
    "\n",
    "        self.screen_width = 800\n",
    "        self.screen_height = 800\n",
    "        self.screen = None\n",
    "        self.state = self._to_s(int((self.H) / 2), int(0.25 * (self.W)))\n",
    "        self.velocity = 1\n",
    "        self.reward = 0\n",
    "        self.collective = 0\n",
    "        \n",
    "    def _to_s(self, row, col):\n",
    "        return row * self.W + col\n",
    "\n",
    "    def step(self, action):\n",
    "        row, col = divmod(self.state, self.W)\n",
    "        prev_row, prev_col = row, col\n",
    "        h_prev = self.grid[row, col]\n",
    "\n",
    "        if self.velocity == 0 or self.collective < -30:  # Check termination conditions\n",
    "            self.reward = -10\n",
    "            self.truncated = True\n",
    "        elif (row == int((self.H) / 2) and col == int(0.75 * self.W)):\n",
    "            self.reward = 0\n",
    "            self.done = True\n",
    "        else:\n",
    "            self.done = False\n",
    "            if action == 0:  # Move left\n",
    "                col = max(col - 1, 0)\n",
    "            elif action == 1:  # Move down\n",
    "                row = min(row + 1, self.H - 1)\n",
    "            elif action == 2:  # Move right\n",
    "                col = min(col + 1, self.W - 1)\n",
    "            elif action == 3:  # Move up\n",
    "                row = max(row - 1, 0)\n",
    "\n",
    "            if ((prev_col - col + prev_row - row) == 0):\n",
    "                self.reward = -1\n",
    "            else:\n",
    "                self.reward = -float(self.stepsize / self.velocity)\n",
    "\n",
    "            h_new = self.grid[row, col]\n",
    "            update_vel = self.velocity ** 2 + 2 * self.gravity * (h_prev - h_new)\n",
    "            if update_vel < 0:\n",
    "                self.velocity = 0\n",
    "            else:\n",
    "                self.velocity = sqrt(update_vel)\n",
    "            \n",
    "            self.state = self._to_s(row, col)\n",
    "            self.collective += self.reward\n",
    "\n",
    "        return self.state, self.reward, self.done, self.truncated, {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            self.screen.fill((255, 255, 255))\n",
    "\n",
    "            for i in range(self.W):\n",
    "                for j in range(self.H):\n",
    "                    x = i * (self.screen_width / self.W)\n",
    "                    y = j * (self.screen_height / self.H)\n",
    "                    color_index = int(self.grid[i, j] * 255)\n",
    "                    color = (255 - color_index, 0, color_index)\n",
    "                    pygame.draw.rect(self.screen, color, (x, y, self.screen_width / self.W, self.screen_height / self.H))\n",
    "            \n",
    "            agent_row, agent_col = divmod(self.state, self.W)\n",
    "            agent_x = agent_col * (self.screen_width / self.W)\n",
    "            agent_y = agent_row * (self.screen_height / self.H) + (self.screen_height / self.H) / 2\n",
    "            pygame.draw.circle(self.screen, (0, 0, 0), (int(agent_x), int(agent_y)), 10)\n",
    "            pygame.display.flip()\n",
    "        \n",
    "        else:\n",
    "            agent_row, agent_col = divmod(self.state, self.W)\n",
    "            agent_x = agent_col * (self.screen_width / self.W)\n",
    "            agent_y = agent_row * (self.screen_height / self.H) + (self.screen_height / self.H) / 2\n",
    "            pygame.draw.circle(self.screen, (0, 0, 0), (int(agent_x), int(agent_y)), 10)\n",
    "            pygame.display.flip()\n",
    "\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            pygame.quit()\n",
    "            self.screen = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self._to_s(int((self.H) / 2), int(0.25 * (self.W)))\n",
    "        self.velocity = 1\n",
    "        self.reward = 0\n",
    "        self.truncated = False\n",
    "        self.done = False\n",
    "        self.collective = 0\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Surface(800x800x32 SW)>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env=rlEnv(20,20)\n",
    "env.render()\n",
    "pygame.time.wait(1000)\n",
    "print(env.screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The reset() method must accept a `seed` parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:421\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 421\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: rlEnv.reset() got an unexpected keyword argument 'seed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_checker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_env\n\u001b[1;32m----> 2\u001b[0m check_env(env)\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:423\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    421\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe reset() method must accept a `seed` parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Warn the user if needed.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# A warning means that the environment may run but not work properly with Stable Baselines algorithms\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m warn:\n",
      "\u001b[1;31mTypeError\u001b[0m: The reset() method must accept a `seed` parameter"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "SNAKE_LEN_GOAL = 30\n",
    "\n",
    "def collision_with_apple(apple_position, score):\n",
    "\tapple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "\tscore += 1\n",
    "\treturn apple_position, score\n",
    "\n",
    "def collision_with_boundaries(snake_head):\n",
    "\tif snake_head[0]>=500 or snake_head[0]<0 or snake_head[1]>=500 or snake_head[1]<0 :\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def collision_with_self(snake_position):\n",
    "\tsnake_head = snake_position[0]\n",
    "\tif snake_head in snake_position[1:]:\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "\n",
    "class SnekEnv(gym.Env):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SnekEnv, self).__init__()\n",
    "\t\t# Define action and observation space\n",
    "\t\t# They must be gym.spaces objects\n",
    "\t\t# Example when using discrete actions:\n",
    "\t\tself.action_space = spaces.Discrete(4)\n",
    "\t\t# Example for using image as input (channel-first; channel-last also works):\n",
    "\t\tself.observation_space = spaces.Box(low=-500, high=500,\n",
    "\t\t\t\t\t\t\t\t\t\t\tshape=(5+SNAKE_LEN_GOAL,), dtype=np.float32)\n",
    "\n",
    "\tdef step(self, action):\n",
    "\t\tself.prev_actions.append(action)\n",
    "\t\tcv2.imshow('a',self.img)\n",
    "\t\tcv2.waitKey(1)\n",
    "\t\tself.img = np.zeros((500,500,3),dtype='uint8')\n",
    "\t\t# Display Apple\n",
    "\t\tcv2.rectangle(self.img,(self.apple_position[0],self.apple_position[1]),(self.apple_position[0]+10,self.apple_position[1]+10),(0,0,255),3)\n",
    "\t\t# Display Snake\n",
    "\t\tfor position in self.snake_position:\n",
    "\t\t\tcv2.rectangle(self.img,(position[0],position[1]),(position[0]+10,position[1]+10),(0,255,0),3)\n",
    "\t\t\n",
    "\t\t# Takes step after fixed time\n",
    "\t\tt_end = time.time() + 0.05\n",
    "\t\tk = -1\n",
    "\t\twhile time.time() < t_end:\n",
    "\t\t\tif k == -1:\n",
    "\t\t\t\tk = cv2.waitKey(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\tbutton_direction = action\n",
    "\t\t# Change the head position based on the button direction\n",
    "\t\tif button_direction == 1:\n",
    "\t\t\tself.snake_head[0] += 10\n",
    "\t\telif button_direction == 0:\n",
    "\t\t\tself.snake_head[0] -= 10\n",
    "\t\telif button_direction == 2:\n",
    "\t\t\tself.snake_head[1] += 10\n",
    "\t\telif button_direction == 3:\n",
    "\t\t\tself.snake_head[1] -= 10\n",
    "\n",
    "\t\t# Increase Snake length on eating apple\n",
    "\t\tif self.snake_head == self.apple_position:\n",
    "\t\t\tself.apple_position, self.score = collision_with_apple(self.apple_position, self.score)\n",
    "\t\t\tself.snake_position.insert(0,list(self.snake_head))\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tself.snake_position.insert(0,list(self.snake_head))\n",
    "\t\t\tself.snake_position.pop()\n",
    "\t\t\n",
    "\t\t# On collision kill the snake and print the score\n",
    "\t\tif collision_with_boundaries(self.snake_head) == 1 or collision_with_self(self.snake_position) == 1:\n",
    "\t\t\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\t\t\tself.img = np.zeros((500,500,3),dtype='uint8')\n",
    "\t\t\tcv2.putText(self.img,'Your Score is {}'.format(self.score),(140,250), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\t\t\tcv2.imshow('a',self.img)\n",
    "\t\t\tself.done = True\n",
    "\n",
    "\t\tself.total_reward = len(self.snake_position) - 3  # default length is 3\n",
    "\t\tself.reward = self.total_reward - self.prev_reward\n",
    "\t\tself.prev_reward = self.total_reward\n",
    "\n",
    "\t\tif self.done:\n",
    "\t\t\tself.reward = -10\n",
    "\t\tinfo = {}\n",
    "\n",
    "\n",
    "\t\thead_x = self.snake_head[0]\n",
    "\t\thead_y = self.snake_head[1]\n",
    "\n",
    "\t\tsnake_length = len(self.snake_position)\n",
    "\t\tapple_delta_x = self.apple_position[0] - head_x\n",
    "\t\tapple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "\t\t# create observation:\n",
    "\n",
    "\t\tobservation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions)\n",
    "\t\tobservation = np.array(observation)\n",
    "\n",
    "\t\treturn observation, self.reward, self.done, info\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.img = np.zeros((500,500,3),dtype='uint8')\n",
    "\t\t# Initial Snake and Apple position\n",
    "\t\tself.snake_position = [[250,250],[240,250],[230,250]]\n",
    "\t\tself.apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "\t\tself.score = 0\n",
    "\t\tself.prev_button_direction = 1\n",
    "\t\tself.button_direction = 1\n",
    "\t\tself.snake_head = [250,250]\n",
    "\n",
    "\t\tself.prev_reward = 0\n",
    "\n",
    "\t\tself.done = False\n",
    "\n",
    "\t\thead_x = self.snake_head[0]\n",
    "\t\thead_y = self.snake_head[1]\n",
    "\n",
    "\t\tsnake_length = len(self.snake_position)\n",
    "\t\tapple_delta_x = self.apple_position[0] - head_x\n",
    "\t\tapple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "\t\tself.prev_actions = deque(maxlen = SNAKE_LEN_GOAL)  # however long we aspire the snake to be\n",
    "\t\tfor i in range(SNAKE_LEN_GOAL):\n",
    "\t\t\tself.prev_actions.append(-1) # to create history\n",
    "\n",
    "\t\t# create observation:\n",
    "\t\tobservation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions)\n",
    "\t\tobservation = np.array(observation)\n",
    "\n",
    "\t\treturn observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The reset() method must accept a `seed` parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:421\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 421\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: SnekEnv.reset() got an unexpected keyword argument 'seed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m env \u001b[38;5;241m=\u001b[39m SnekEnv()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# It will check your custom environment and output additional warnings if needed\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m check_env(env)\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:423\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    421\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe reset() method must accept a `seed` parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Warn the user if needed.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# A warning means that the environment may run but not work properly with Stable Baselines algorithms\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m warn:\n",
      "\u001b[1;31mTypeError\u001b[0m: The reset() method must accept a `seed` parameter"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "\n",
    "env = SnekEnv()\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SnekEnv.reset() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m \titers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 26\u001b[0m \tmodel\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mTIMESTEPS, reset_num_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tb_log_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \tmodel\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTIMESTEPS\u001b[38;5;241m*\u001b[39miters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    316\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    317\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    318\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    319\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    320\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    321\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:264\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[0;32m    255\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[0;32m    262\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 264\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_learn(\n\u001b[0;32m    265\u001b[0m         total_timesteps,\n\u001b[0;32m    266\u001b[0m         callback,\n\u001b[0;32m    267\u001b[0m         reset_num_timesteps,\n\u001b[0;32m    268\u001b[0m         tb_log_name,\n\u001b[0;32m    269\u001b[0m         progress_bar,\n\u001b[0;32m    270\u001b[0m     )\n\u001b[0;32m    272\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:423\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:77\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m     76\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m---> 77\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manis\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: SnekEnv.reset() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "# from snakeenv import SnekEnv\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "models_dir = f\"models/{int(time.time())}/\"\n",
    "logdir = f\"logs/{int(time.time())}/\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "\tos.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "\tos.makedirs(logdir)\n",
    "\n",
    "env = SnekEnv()\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=logdir)\n",
    "\n",
    "TIMESTEPS = 10000\n",
    "iters = 0\n",
    "while True:\n",
    "\titers += 1\n",
    "\tmodel.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\")\n",
    "\tmodel.save(f\"{models_dir}/{TIMESTEPS*iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
